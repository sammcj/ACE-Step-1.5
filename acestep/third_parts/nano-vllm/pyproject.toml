[build-system]
requires = ["setuptools>=61"]
build-backend = "setuptools.build_meta"

[project]
name = "nano-vllm"
version = "0.2.0"
authors = [{ name = "Xingkai Yu" }]
license = {text = "MIT"}
readme = "README.md"
description = "a lightweight vLLM implementation built from scratch"
requires-python = ">=3.10,<3.13"
dependencies = [
    "torch>=2.4.0",
    # Triton is optional; Flash Attention is intentionally omitted from required deps.
    # flash-attn is an optional performance enhancement - the SDPA fallback is used when
    # flash-attn is not installed. Omitting the URL-based wheels here prevents uv from
    # downloading large wheel files (~240 MB each) on all platforms (including macOS ARM64)
    # during cross-platform lock file resolution. Users who need flash-attn for maximum
    # performance on CUDA platforms can install it separately:
    #   pip install flash-attn
    "triton-windows>=3.0.0,<3.4; sys_platform == 'win32' and python_version == '3.11'",
    "triton>=3.0.0; sys_platform == 'linux' and python_version == '3.11'",
    "transformers>=4.51.0",
    "xxhash",
]

[project.urls]
Homepage="https://github.com/GeeeekExplorer/nano-vllm"

[tool.setuptools.packages.find]
where = ["."]
include = ["nanovllm*"]
